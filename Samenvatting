0.	Voorbereiding
	CONLL2002 corpus â€“ ned.train file gebruiken om de modellen te trainen.
1.	Stap 1: Minimale NER tagger
	custom_chunker.py (gegeven) gebruiken om een entity recognizer te trainen. Daarna:
	-	Pickle de entity (10.6)
	-	Meet de performance (12.1.4)
2.	Stap 2: Script
	-	Custom_chunker.py (gegeven, niks veranderen)
o	Nodig: training dataset of chunked sentences and a feature extractor function die intern wordt 		gebruikt tijdens training en normaal gebruik.
	-	Features.py
		o	Features_simple_1(sentence, i, history)
			Tagged sentence, index i van een woord in de sentence, lijst history met de IOB tags
			Must return dictionary van de extracted features (welke features?)
			Hierna kunnen we een recognizer trainen
		o 	evaluate()
			Recognizer evalueren --> ned.testa
	Je kan nu beide modules importeren.
3.	Na het picklen mag je de functies en klassen niet veranderen.
	Gebruik een andere naam voor elke versie van de feature extraction functie.
	Alle nodige klassen en functies moeten worden gedefinieerd in modules en geimporteerd in de main script.
4.	Self-testing
	- model_test.py (gegeven, niks veranderen)
5.	Stap 3: Feature selectie verbeteren
	Trainen met ned.train en evalueren met ned.testa.
	Vb: Capitalization informatie, aantal letters, tags, of  het een woord volgt dat al gemarkeerd is als deel van een entity, etc.
	Externe bronnen zijn toegestaan.
	Je hoeft niet elke versie te reporten, maar wel meer dan een demonstratie.
6.	Stap 4: Machine learning engines vergelijken
	custom_chunker gebruikt de MaxEnt classifier. 
	Je kan een leeralgoritme selecteren door het algorithm argument van ConsecutiveNPChunker te gebruiken. Alle beschikbare algoritmen zien: print(nltk.classify.MaxentClassifier.ALGORITHMS).
	Werk met IIS, GIS en NaiveBayes classifier. Voor NaiveBayes moet je dingen veranderen in custom_chunker.
7.	Stap 5: Performance evaluatie
	Train de beste classifier op ned.train, pickle het en evalueer het op de data in ned.testa. Stop het in een verslag. 
	- Je kan ConfusionMatrix() gebruiken om fouten te identificeren.
	- ChunkScore() kan handig zijn.
	Baseline: 6 features met 60% performance. 
8. 	Stap 6: Submissie 
	Files:
	- BuildModels.py - Trains en pickles de verschillende classifiers.
	- EvaluateModels.py - Laad en evalueert de modellen. Het moet in ieder geval printen:
		o 	Iets dat de model/feature set identificeert
		o 	Precisie
		o 	Recall
		o 	F-score
		o 	Meer is aangeraden
	- features.py - Definieert of importeert een of meerdere feature extractor functies.
	- custom_chunker.py
	- Evaluation-output.txt met de opgeslagen output van de evaluatie.
	- Andere files met externe data.

	- Best.pickle - Pickled model van de beste classifier. Test of het kan worden reloaded met model_test (het aanpassen hiervan is aftrek).
	- Kort verslag met onze bevindingen van stap 4.


Pickle = module which allows us to write out and later restore large, complex objects very easily. Pickling stores only data, not functions or class definitions.